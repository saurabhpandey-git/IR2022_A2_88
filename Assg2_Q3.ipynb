{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d41299",
   "metadata": {
    "id": "65d41299"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18679723",
   "metadata": {
    "id": "18679723"
   },
   "outputs": [],
   "source": [
    "# 5 Classes\n",
    "labelToNum = {'comp.graphics': 0, 'sci.med': 1, 'talk.politics.misc': 2, 'rec.sport.hockey': 3, 'sci.space': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61e6e58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c61e6e58",
    "outputId": "c1f5fe17-da5c-49dd-c688-5aa9ba4384ef"
   },
   "outputs": [],
   "source": [
    "path = \"20_newsgroups/\"\n",
    "\n",
    "docs = []\n",
    "labels = []\n",
    "\n",
    "# For subfolders in folders.\n",
    "for doc in os.listdir(path):\n",
    "    # only requested folders.\n",
    "    if doc in labelToNum:\n",
    "        #print(doc)\n",
    "        subDir = os.listdir(path+\"/\"+doc)\n",
    "        for ins_doc in subDir:\n",
    "            #print(ins_doc)\n",
    "            f = open(path+\"/\"+doc+\"/\"+ins_doc, 'r', encoding =\"ascii\", errors =\"surrogateescape\")\n",
    "            docs.append(f.read())\n",
    "            labels.append(labelToNum[doc])\n",
    "        \n",
    "docs = np.array(docs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf5cae",
   "metadata": {
    "id": "cabf5cae"
   },
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d18049",
   "metadata": {
    "id": "67d18049"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d156fe5e",
   "metadata": {
    "id": "d156fe5e"
   },
   "outputs": [],
   "source": [
    "def preprocessing(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'[^a-zA-Z0-9]+', ' ', sent)\n",
    "    sent = [w for w in sent.split() if w not in stopWords]\n",
    "    sent = [w for w in sent if len(w) > 2]\n",
    "    sent = [lemmatizer.lemmatize(w) for w in sent]\n",
    "    return \" \".join(sent).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e63cc17",
   "metadata": {
    "id": "9e63cc17"
   },
   "outputs": [],
   "source": [
    "for i,d in enumerate(docs):\n",
    "    docs[i] = preprocessing(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4c87c",
   "metadata": {
    "id": "03f4c87c"
   },
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81d20fd",
   "metadata": {
    "id": "b81d20fd"
   },
   "outputs": [],
   "source": [
    "#np.random.choice(80, size=50)\n",
    "def trainTestSplit(ratio = 0.6):\n",
    "    # Compute length\n",
    "    len_of_train = int(docs.shape[0] * ratio)\n",
    "    # Get train indices randomly.\n",
    "    index_of_train = np.random.choice(docs.shape[0], size=len_of_train)\n",
    "    \n",
    "    # return data\n",
    "    return (docs[index_of_train], \n",
    "            labels[index_of_train], \n",
    "            docs[np.setdiff1d(range(docs.shape[0]), index_of_train)], \n",
    "            labels[np.setdiff1d(range(docs.shape[0]), index_of_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f99a65b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f99a65b",
    "outputId": "1e4842a6-21c9-4ea8-d92e-8402fa7aa799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size:  3000 3000\n",
      "Test Data Size:  2752 2752\n"
     ]
    }
   ],
   "source": [
    "train, trainLabel, test, testLabel = trainTestSplit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115551c",
   "metadata": {
    "id": "d115551c"
   },
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b278b60",
   "metadata": {
    "id": "3b278b60"
   },
   "outputs": [],
   "source": [
    "\n",
    "ClassFreq = {}\n",
    "for j,k in enumerate(train):\n",
    "    for word in k.split(\" \"):\n",
    "        if word not in ClassFreq:\n",
    "            ClassFreq[word] = set()\n",
    "        ClassFreq[word].add(labels[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414357da",
   "metadata": {
    "id": "414357da"
   },
   "outputs": [],
   "source": [
    "InverseClassFreq = {}\n",
    "length=len(ClassFreq[word]\n",
    "for word in ClassFreq.keys():\n",
    "    InverseClassFreq[word] = math.log(5/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "FwGQ3Ms8wESA",
   "metadata": {
    "id": "FwGQ3Ms8wESA"
   },
   "outputs": [],
   "source": [
    "def count_term_freq(term_freq,train,trainLabel):\n",
    "    for i,sent in enumerate(train):\n",
    "        for w in sent.split(\" \"):\n",
    "            if w not in term_freq[trainLabel[i]]:\n",
    "                term_freq[trainLabel[i]][w] = 0\n",
    "            term_freq[trainLabel[i]][w] += 1\n",
    "\n",
    "    return term_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf48ba6",
   "metadata": {
    "id": "9bf48ba6"
   },
   "outputs": [],
   "source": [
    "term_freq = {0: {}, 1: {}, 2: {}, 3: {}, 4: {}}\n",
    "term_freq = count_term_freq(term_freq,train,trainLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208c20ad",
   "metadata": {
    "id": "208c20ad"
   },
   "outputs": [],
   "source": [
    "tf_icf = {}\n",
    "for i in range(0,5):\n",
    "    tf_icf[i] = {}\n",
    "    for w in term_freq[i]:\n",
    "        tf_icf[i][w] = term_freq[i][w] * InverseClassFreq[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98029ed2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98029ed2",
    "outputId": "79411230-3752-46e0-ec07-0eff8b6427cd"
   },
   "outputs": [],
   "source": [
    "k = 200\n",
    "features = set()\n",
    "for i in range(5):\n",
    "    z = list(dict(sorted(tf_icf[i].items(), key=lambda y: y[1], reverse=True)).keys())\n",
    "    features = features.union(set(z[:k]))\n",
    "vocab = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae1a8445",
   "metadata": {
    "id": "ae1a8445"
   },
   "outputs": [],
   "source": [
    "def generateNewData(data, vocab):\n",
    "    updatedData = []\n",
    "    for text in data:\n",
    "        newText = []\n",
    "        for word in text.split(\" \"):\n",
    "            if word in vocab:\n",
    "                newText.append(word)\n",
    "        updatedData.append(\" \".join(newText).strip())\n",
    "        \n",
    "    return updatedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68a34aa2",
   "metadata": {
    "id": "68a34aa2"
   },
   "outputs": [],
   "source": [
    "def generateFeatures(train_data, test_data):\n",
    "    vect = TfidfVectorizer()\n",
    "    A = vect.fit_transform(train_data)\n",
    "    B = vect.transform(test_data)\n",
    "    return (A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d5e030",
   "metadata": {
    "id": "42d5e030"
   },
   "outputs": [],
   "source": [
    "train = generateNewData(train, vocab)\n",
    "test = generateNewData(test, vocab)\n",
    "(train, test) = generateFeatures(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ac669",
   "metadata": {
    "id": "ee2ac669"
   },
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "149a83ca",
   "metadata": {
    "id": "149a83ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naiveBayesModel = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df51c715",
   "metadata": {
    "id": "df51c715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayesModel.fit(train.toarray(),trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d56dc18f",
   "metadata": {
    "id": "d56dc18f"
   },
   "outputs": [],
   "source": [
    "predict_train = naiveBayesModel.predict(train.toarray())\n",
    "predict_test = naiveBayesModel.predict(test.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a41d4c",
   "metadata": {
    "id": "84a41d4c"
   },
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04758b43",
   "metadata": {
    "id": "04758b43",
    "outputId": "a41bfb4e-dbaf-41b2-dec8-8dbbc1c62bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9731428571428572\n",
      "Test Accuracy:  0.9218623481781376\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", sum(predict_train == trainLabel)/len(trainLabel))\n",
    "print(\"Test Accuracy: \", sum(predict_test == testLabel)/len(testLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ee63cdc",
   "metadata": {
    "id": "0ee63cdc",
    "outputId": "fe35bb98-2c04-450a-b0a6-317ca2fd0a3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471,  13,   0,   0,  12],\n",
       "       [114, 371,   0,   0,  15],\n",
       "       [ 22,   9, 474,   1,  10],\n",
       "       [ 30,   0,   0, 451,   0],\n",
       "       [ 68,   5,   3,   0, 401]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(testLabel,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7d3b9",
   "metadata": {
    "id": "bed7d3b9"
   },
   "source": [
    "### 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff8d80",
   "metadata": {
    "id": "a0ff8d80"
   },
   "source": [
    "##### 50-50 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32aa2bda",
   "metadata": {
    "id": "32aa2bda",
    "outputId": "ac05d5bd-42d2-493d-8099-5c875cfd3df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9808\n",
      "Test Accuracy:  0.9230769230769231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[528,  35,   0,   0,  32],\n",
       "       [ 48, 522,  18,   1,   4],\n",
       "       [  2,  19, 582,   3,  17],\n",
       "       [  0,   2,   8, 585,   3],\n",
       "       [ 20,  10,  10,   1, 579]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = trainTestSplit(0.5)\n",
    "\n",
    "trainX = generateNewData(trainX, vocab)\n",
    "testX = generateNewData(testX, vocab)\n",
    "(trainX, testX) = generateFeatures(trainX, testX)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(trainX.toarray(), trainy)\n",
    "x = model.predict(trainX.toarray())\n",
    "y = model.predict(testX.toarray())\n",
    "print(\"Train Accuracy: \", sum(x == trainy)/len(trainy))\n",
    "print(\"Test Accuracy: \", sum(y == testy)/len(testy))\n",
    "confusion_matrix(testy,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105585f",
   "metadata": {
    "id": "e105585f"
   },
   "source": [
    "##### 70-30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51259e17",
   "metadata": {
    "id": "51259e17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9694285714285714\n",
      "Test Accuracy:  0.9113100081366965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[452,  22,   0,   2,  29],\n",
       "       [ 46, 427,  20,   0,  15],\n",
       "       [  3,   9, 480,   0,  17],\n",
       "       [  1,   3,   6, 470,   0],\n",
       "       [ 18,   7,  20,   0, 411]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = trainTestSplit(0.7)\n",
    "\n",
    "trainX = generateNewData(trainX, vocab)\n",
    "testX = generateNewData(testX, vocab)\n",
    "(trainX, testX) = generateFeatures(trainX, testX)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(trainX.toarray(), trainy)\n",
    "x = model.predict(trainX.toarray())\n",
    "y = model.predict(testX.toarray())\n",
    "\n",
    "print(\"Train Accuracy: \", sum(x == trainy)/len(trainy))\n",
    "print(\"Test Accuracy: \", sum(y == testy)/len(testy))\n",
    "confusion_matrix(testy,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13066ad0",
   "metadata": {
    "id": "13066ad0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ae49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assg2_Q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
